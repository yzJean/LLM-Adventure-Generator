from sqlalchemy.orm import Session
from core.config import settings

from langchain_openai import ChatOpenAI
from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import PydanticOutputParser

from core.prompts import STORY_PROMPT
from models.story import Story, StoryNode
from core.models import StoryLLMResponse, StoryNodeLLM
from dotenv import load_dotenv
load_dotenv() # load .env file to get the environment variables for the current script, such as OPENAI_API

class StoryGenerator:

    @classmethod
    def _get_llm(cls): # In Python, with a prefix underscore, it is a private method in this class
        return ChatOpenAI(model="gpt-4o")

    @classmethod
    def generate_story(cls, db: Session, session_id: str, theme: str = "fantasy") -> Story:
        llm = cls._get_llm()
        # PydanticOutputParser creates a parser that knows how to convert LLM responses into StoryLLMResponse Pydantic objects. pydantic_object=StoryLLMResponse tells it: "I expect the LLM to return data matching this schema"
        story_parser = PydanticOutputParser(pydantic_object=StoryLLMResponse)

        # format_instructions is specified in the prompt
        # get_format_instructions() gives us a string following the format defined in the StoryLLMResponse
        prompt = ChatPromptTemplate.from_messages([
            ("system", STORY_PROMPT),
            ("human", f"Create the story with this theme: {theme}")
        ]).partial(format_instructions=story_parser.get_format_instructions())


        # We don't need to pass any information to the prompt, so we pass an empty dictionary to the invoke() method
        raw_response = llm.invoke(prompt.invoke({}))

        response_text = raw_response
        if hasattr(raw_response, "content"):
            response_text = raw_response.content

        story_structure = story_parser.parse(response_text)
        """
            response_text (raw JSON string)
                ↓
            Parser reads the string
                ↓
            Converts to Python dict
                ↓
            Validates against StoryLLMResponse schema
                ↓
            Returns StoryLLMResponse object (story_structure)
        """

        story_db = Story(title=story_structure.title, session_id=session_id)
        db.add(story_db)
        db.flush() # update all the database objects in the current session, so that the story_db object will have the id generated by the database, which we need to use as the foreign key for the story nodes

        root_node_data = story_structure.rootNode
        if isinstance(root_node_data, dict):
            root_node_data = StoryNodeLLM.model_validate(root_node_data) # validate the data and convert it to a StoryNodeLLM object

        cls._process_story_node(db, story_db.id, root_node_data, is_root=True) # process the root node and its child nodes recursively, and save them to the database
        
        db.commit() # commit the story and story nodes to the database
        return story_db

    @classmethod
    # since we got returned massage from LLM in JSON, we need to process the data and save it to the database. This function is to process each node in the story recursively and save it to the database.
    def _process_story_node(cls, db: Session, story_id: int, node_data: StoryNodeLLM, is_root: bool = False) -> StoryNode:
        node = StoryNode(story_id=story_id,
                        content=node_data.content if hasattr(node_data, "content") else node_data["content"],
                        is_root=is_root,
                        is_ending=node_data.isEnding if hasattr(node_data, "isEnding") else node_data["isEnding"],
                        is_winning_ending=node_data.isWinningEnding if hasattr(node_data, "isWinningEnding") else node_data["isWinningEnding"],
                        options=[])
        db.add(node)
        db.flush()

        # store simplified information from the node to the tree data structure
        if not node.is_ending and (hasattr(node_data, "options") and node_data.options):
            options_list = []
            for option_data in node_data.options:
                next_node = option_data.nextNode
                
                if isinstance(next_node, dict):
                    next_node = StoryNodeLLM.model_validate(next_node) # validate the data and convert it to a StoryNodeLLM object
                child_node = cls._process_story_node(db, story_id, next_node, is_root=False) # recursively process the child node
                
                options_list.append({
                    "text": option_data.text,
                    "node_id": child_node.id
                })
            node.options = options_list
        db.flush()
        return node